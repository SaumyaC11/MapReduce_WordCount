Spark Implementation of Word Count using Map Reduce Functionality 

Text documents can sometimes be very lengthy and to understand the similarity between various documents we need algorithms like Apriori and LHS, well Map Reduce is starting point of this algorithms. 
Provide mapping the word to their respective count functionality


Libaries used - Spark


~ Saumya Chaudhary
